If two brand new teams play a game what information can we gather from the result? We know who won the game and so we should probably assume that the victor is the better team. But are they the best team ever? Or is the losing team the worst team ever? Or did the losing team just get really unlucky? We do not want to extrapolate too much from one game, but if we know the results of other games maybe we can actually know something. So how do we analyze an event to help make the best possible prediction of future events?

The only way to make an optimal prediction is if we restrict the available information. Injuries, weather, and a million other factors can contribute to an outcome so we will always be able to improve our model. But before we add in these other factors it would be beneficial if we could get the maximum value out of the basics. So we will try to make predictions only knowing the scores of previous games. And we need to make assumptions about the distribution of abilities and final scores. Restricting to this particular scenario allows for the creation of a theoretically optimal prediction, but this prediction should also be very good in the real world.

We want to assign a rating to each team that allows for an easy comparison between teams to create a point spread and probability of victory computation. I.e. if team A has a rating of 6012 and team B has a rating of 6009 then we would like to be able to say that team A is expected to win by 3 points and use some formula to determine that team A will win 60% of the time or whatever the case may be. ELO ratings have already been calibrated in this manner so we will borrow their scale which means an average team will have a rating of 1500.

Initially we assign everyone a rating of 1500 because we don't know any better, but what happens after the first game? We don't know if this matchup was between the two best teams in the league or the two worst teams. The 1500 rating was really just a placeholder and our confidence in its predictive abilities is low. Maybe instead of assigning a fixed rating to each team we should assign a distribution of ratings. Thus each team is not a 1500, but each team has a low probability of being a 1200 or 1800 and a higher probability of being rated in the middle. This system is more accurate because it actually matches reality. Without any information about the players or coaches we cannot do any better than to assume that the team's rating matches the overall distribution of ratings.

If a team continuously loses to teams ranked above 1500 and beats teams ranked below 1500 then we can say with much more certainty that a rating of 1500 is accurate. And our rating system should be able to reflect this difference between an initial 1500 based on no information and a team that has earned their 1500 rating. Now that we have distribution ratings we can learn even more about each matchup, but our math is going to be more complicated.